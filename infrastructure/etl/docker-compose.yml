# AtlasMesh Fleet OS - ETL Data Pipelines
# Apache Spark jobs, dbt transformations, data quality monitoring, lineage tracking

version: '3.8'

services:
  # Apache Spark Master
  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT_NUMBER=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "8080:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master Port
    volumes:
      - ./spark/conf:/opt/bitnami/spark/conf
      - ./spark/jobs:/opt/spark-jobs
      - ./spark/data:/opt/spark-data
      - spark-master-logs:/opt/bitnami/spark/logs
    networks:
      - etl-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Apache Spark Worker 1
  spark-worker-1:
    image: bitnami/spark:3.5
    container_name: spark-worker-1
    hostname: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./spark/conf:/opt/bitnami/spark/conf
      - ./spark/jobs:/opt/spark-jobs
      - ./spark/data:/opt/spark-data
      - spark-worker-1-logs:/opt/bitnami/spark/logs
    networks:
      - etl-network
    depends_on:
      - spark-master
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # Apache Spark Worker 2
  spark-worker-2:
    image: bitnami/spark:3.5
    container_name: spark-worker-2
    hostname: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./spark/conf:/opt/bitnami/spark/conf
      - ./spark/jobs:/opt/spark-jobs
      - ./spark/data:/opt/spark-data
      - spark-worker-2-logs:/opt/bitnami/spark/logs
    networks:
      - etl-network
    depends_on:
      - spark-master
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # Apache Spark History Server
  spark-history-server:
    image: bitnami/spark:3.5
    container_name: spark-history-server
    hostname: spark-history-server
    environment:
      - SPARK_MODE=history-server
      - SPARK_HISTORY_FS_LOGDIRECTORY=/opt/spark-events
    ports:
      - "18080:18080"  # Spark History Server Web UI
    volumes:
      - ./spark/conf:/opt/bitnami/spark/conf
      - spark-events:/opt/spark-events
      - spark-history-logs:/opt/bitnami/spark/logs
    networks:
      - etl-network
    depends_on:
      - spark-master
    restart: unless-stopped

  # dbt (Data Build Tool) Service
  dbt-service:
    build:
      context: .
      dockerfile: Dockerfile.dbt
    container_name: dbt-service
    environment:
      - DBT_PROFILES_DIR=/root/.dbt
      - DBT_PROJECT_DIR=/app/dbt_project
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=${POSTGRES_PORT:-5432}
      - POSTGRES_DB=${POSTGRES_DB:-atlasmesh_fleet_os}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - CLICKHOUSE_HOST=${CLICKHOUSE_HOST:-clickhouse-01}
      - CLICKHOUSE_PORT=${CLICKHOUSE_PORT:-9000}
      - CLICKHOUSE_DB=${CLICKHOUSE_DB:-atlasmesh_analytics}
      - CLICKHOUSE_USER=${CLICKHOUSE_USER:-analytics_user}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
    volumes:
      - ./dbt:/app/dbt_project
      - ./dbt/profiles:/root/.dbt
      - dbt-logs:/app/logs
    networks:
      - etl-network
    ports:
      - "8081:8080"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "dbt", "--version"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Apache Airflow (Workflow Orchestration)
  airflow-webserver:
    image: apache/airflow:2.7.0-python3.11
    container_name: airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow_password@airflow-postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs=
      - AIRFLOW__WEBSERVER__SECRET_KEY=secret_key_2024
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK=true
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
    ports:
      - "8082:8080"
    networks:
      - etl-network
    depends_on:
      - airflow-postgres
    restart: unless-stopped
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Airflow Scheduler
  airflow-scheduler:
    image: apache/airflow:2.7.0-python3.11
    container_name: airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow_password@airflow-postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs=
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK=true
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
    networks:
      - etl-network
    depends_on:
      - airflow-postgres
    restart: unless-stopped
    command: scheduler
    healthcheck:
      test: ["CMD", "airflow", "jobs", "check", "--job-type", "SchedulerJob"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Airflow Database
  airflow-postgres:
    image: postgres:15-alpine
    container_name: airflow-postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow_password
      - POSTGRES_DB=airflow
    volumes:
      - airflow-postgres-data:/var/lib/postgresql/data
    networks:
      - etl-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Data Quality Monitoring Service
  data-quality-service:
    build:
      context: .
      dockerfile: Dockerfile.data-quality
    container_name: data-quality-service
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=${POSTGRES_PORT:-5432}
      - POSTGRES_DB=${POSTGRES_DB:-atlasmesh_fleet_os}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - CLICKHOUSE_HOST=${CLICKHOUSE_HOST:-clickhouse-01}
      - CLICKHOUSE_PORT=${CLICKHOUSE_PORT:-9000}
      - CLICKHOUSE_DB=${CLICKHOUSE_DB:-atlasmesh_analytics}
      - CLICKHOUSE_USER=${CLICKHOUSE_USER:-analytics_user}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
      - KAFKA_BROKERS=${KAFKA_BROKERS:-kafka:9092}
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
      - EMAIL_SMTP_HOST=${EMAIL_SMTP_HOST}
      - ALERT_EMAIL=${ALERT_EMAIL}
    volumes:
      - ./data-quality/rules:/app/rules
      - ./data-quality/reports:/app/reports
      - data-quality-logs:/app/logs
    networks:
      - etl-network
    ports:
      - "8083:8080"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Data Lineage Tracking Service
  data-lineage-service:
    build:
      context: .
      dockerfile: Dockerfile.data-lineage
    container_name: data-lineage-service
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=neo4j_password_2024!
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - CLICKHOUSE_HOST=${CLICKHOUSE_HOST:-clickhouse-01}
      - KAFKA_BROKERS=${KAFKA_BROKERS:-kafka:9092}
    volumes:
      - ./data-lineage/config:/app/config
      - ./data-lineage/schemas:/app/schemas
      - data-lineage-logs:/app/logs
    networks:
      - etl-network
    ports:
      - "8084:8080"
    depends_on:
      - neo4j
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Neo4j for Data Lineage
  neo4j:
    image: neo4j:5.12-community
    container_name: neo4j-lineage
    environment:
      - NEO4J_AUTH=neo4j/neo4j_password_2024!
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=2G
      - NEO4J_dbms_memory_pagecache_size=1G
    ports:
      - "7474:7474"  # Neo4j Browser
      - "7687:7687"  # Bolt protocol
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
      - neo4j-import:/var/lib/neo4j/import
      - neo4j-plugins:/plugins
    networks:
      - etl-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "neo4j_password_2024!", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ETL Job Scheduler
  etl-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.etl-scheduler
    container_name: etl-scheduler
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - CLICKHOUSE_HOST=${CLICKHOUSE_HOST:-clickhouse-01}
      - KAFKA_BROKERS=${KAFKA_BROKERS:-kafka:9092}
      - AIRFLOW_API_URL=http://airflow-webserver:8080/api/v1
      - AIRFLOW_USERNAME=admin
      - AIRFLOW_PASSWORD=admin
      - SCHEDULE_INTERVAL=${ETL_SCHEDULE_INTERVAL:-*/30 * * * *}  # Every 30 minutes
    volumes:
      - ./etl/jobs:/app/jobs
      - ./etl/config:/app/config
      - ./etl/logs:/app/logs
      - ./spark/jobs:/opt/spark-jobs
    networks:
      - etl-network
    ports:
      - "8085:8080"
    depends_on:
      - spark-master
      - airflow-scheduler
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MinIO for Data Lake Storage
  minio:
    image: minio/minio:latest
    container_name: minio-datalake
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin123
      - MINIO_CONSOLE_ADDRESS=:9001
    ports:
      - "9000:9000"  # MinIO API
      - "9001:9001"  # MinIO Console
    volumes:
      - minio-data:/data
    networks:
      - etl-network
    command: server /data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ETL Monitoring Dashboard
  etl-dashboard:
    build:
      context: .
      dockerfile: Dockerfile.etl-dashboard
    container_name: etl-dashboard
    environment:
      - SPARK_MASTER_URL=http://spark-master:8080
      - AIRFLOW_URL=http://airflow-webserver:8080
      - DATA_QUALITY_URL=http://data-quality-service:8080
      - DATA_LINEAGE_URL=http://data-lineage-service:8080
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=neo4j_password_2024!
    volumes:
      - ./dashboard/config:/app/config
      - dashboard-logs:/app/logs
    networks:
      - etl-network
    ports:
      - "8086:8080"
    depends_on:
      - spark-master
      - airflow-webserver
      - data-quality-service
      - data-lineage-service
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  spark-master-logs:
    driver: local
  spark-worker-1-logs:
    driver: local
  spark-worker-2-logs:
    driver: local
  spark-events:
    driver: local
  spark-history-logs:
    driver: local
  dbt-logs:
    driver: local
  airflow-postgres-data:
    driver: local
  data-quality-logs:
    driver: local
  data-lineage-logs:
    driver: local
  neo4j-data:
    driver: local
  neo4j-logs:
    driver: local
  neo4j-import:
    driver: local
  neo4j-plugins:
    driver: local
  minio-data:
    driver: local
  dashboard-logs:
    driver: local

networks:
  etl-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.27.0.0/16
