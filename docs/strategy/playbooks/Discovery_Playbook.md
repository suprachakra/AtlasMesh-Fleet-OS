# Discovery Playbook

**Purpose**: Systematic approach to discovering and validating product opportunities  
**Owner**: PM CoP  
**Version**: [1.0]  
**Last Updated**: [YYYY-MM-DD]

---

## 1. Discovery Framework

### 1.1 Discovery Phases
1. **Problem Discovery** (Week 1)
2. **Solution Discovery** (Week 2)
3. **Validation Discovery** (Week 3)
4. **Synthesis & Decision** (Week 4)

### 1.2 Discovery Principles
- **Evidence-first**: No assumptions without evidence
- **User-centric**: Always start with user needs
- **Hypothesis-driven**: Test specific hypotheses
- **Time-boxed**: Maximum 3 weeks per discovery
- **Collaborative**: Include cross-functional team

---

## 2. Problem Discovery (Week 1)

### 2.1 User Research
**Objective**: Understand user problems and needs

#### User Interviews (5-7 minimum)
- [ ] **Target users identified**
  - [User persona 1]
  - [User persona 2]
  - [User persona 3]
- [ ] **Interview guide created**
  - [Problem discovery questions]
  - [Current solution questions]
  - [Pain point questions]
- [ ] **Interviews conducted**
  - [Interview 1] - [Date] - [User] - [Key insights]
  - [Interview 2] - [Date] - [User] - [Key insights]
  - [Interview 3] - [Date] - [User] - [Key insights]
  - [Interview 4] - [Date] - [User] - [Key insights]
  - [Interview 5] - [Date] - [User] - [Key insights]
- [ ] **Interview synthesis completed**
  - [Key themes identified]
  - [Pain points prioritized]
  - [User needs documented]

#### Telemetry Analysis
- [ ] **Data sources identified**
  - [Telemetry source 1]
  - [Telemetry source 2]
  - [Telemetry source 3]
- [ ] **30-day data slice analyzed**
  - [Baseline metrics established]
  - [Trends identified]
  - [Anomalies noted]
- [ ] **Gap analysis completed**
  - [Current state vs desired state]
  - [Improvement opportunities]
  - [Quantified impact]

#### Support Ticket Analysis
- [ ] **Support tickets reviewed**
  - [Ticket category 1]: [Count] tickets
  - [Ticket category 2]: [Count] tickets
  - [Ticket category 3]: [Count] tickets
- [ ] **Common themes identified**
  - [Theme 1]: [Frequency] - [Impact]
  - [Theme 2]: [Frequency] - [Impact]
  - [Theme 3]: [Frequency] - [Impact]

### 2.2 Problem Validation
**Objective**: Validate that problems are real and significant

#### Problem Statement
- [ ] **Problem clearly defined**
  - [Who] has [problem] when [situation]
  - [Impact] is [quantified impact]
  - [Frequency] is [how often]
- [ ] **Problem severity assessed**
  - [High/Medium/Low] severity
  - [Justification for severity rating]
- [ ] **Problem scope defined**
  - [Geographic scope]
  - [User segment scope]
  - [Time scope]

#### Market Validation
- [ ] **Market size estimated**
  - [TAM]: [Size]
  - [SAM]: [Size]
  - [SOM]: [Size]
- [ ] **Competitive landscape analyzed**
  - [Direct competitors]: [List]
  - [Indirect competitors]: [List]
  - [Competitive gaps]: [List]

---

## 3. Solution Discovery (Week 2)

### 3.1 Solution Ideation
**Objective**: Generate and evaluate solution concepts

#### Brainstorming Sessions
- [ ] **Cross-functional team assembled**
  - [PM, Design, Engineering, etc.]
- [ ] **Solution concepts generated**
  - [Concept 1]: [Description]
  - [Concept 2]: [Description]
  - [Concept 3]: [Description]
- [ ] **Concepts evaluated**
  - [Feasibility assessment]
  - [Impact assessment]
  - [Effort assessment]

#### Solution Validation
- [ ] **User feedback on concepts**
  - [Concept 1 feedback]: [Summary]
  - [Concept 2 feedback]: [Summary]
  - [Concept 3 feedback]: [Summary]
- [ ] **Technical feasibility validated**
  - [Architecture review]
  - [Integration assessment]
  - [Performance considerations]

### 3.2 Solution Design
**Objective**: Design detailed solution approach

#### Solution Architecture
- [ ] **High-level architecture designed**
  - [System components]
  - [Data flows]
  - [Integration points]
- [ ] **Technical approach defined**
  - [Technology choices]
  - [Implementation approach]
  - [Performance requirements]

#### User Experience Design
- [ ] **User journey mapped**
  - [Current state journey]
  - [Future state journey]
  - [Improvement points]
- [ ] **Wireframes/mockups created**
  - [Key screens designed]
  - [User flows documented]
  - [Interaction patterns defined]

---

## 4. Validation Discovery (Week 3)

### 4.1 Solution Validation
**Objective**: Validate that proposed solution will work

#### User Testing
- [ ] **Prototype/mockup created**
  - [Fidelity level]
  - [Key features included]
  - [User scenarios covered]
- [ ] **User testing conducted**
  - [Test 1]: [User] - [Results]
  - [Test 2]: [User] - [Results]
  - [Test 3]: [User] - [Results]
- [ ] **Feedback synthesized**
  - [Key insights]
  - [Usability issues]
  - [Feature priorities]

#### Technical Validation
- [ ] **Proof of concept developed**
  - [Technical feasibility proven]
  - [Performance validated]
  - [Integration tested]
- [ ] **Risk assessment completed**
  - [Technical risks identified]
  - [Mitigation strategies defined]
  - [Contingency plans created]

### 4.2 Business Validation
**Objective**: Validate business case and impact

#### Financial Modeling
- [ ] **Revenue impact estimated**
  - [Direct revenue impact]
  - [Indirect revenue impact]
  - [Revenue timeline]
- [ ] **Cost impact estimated**
  - [Development costs]
  - [Operational costs]
  - [Opportunity costs]
- [ ] **ROI calculated**
  - [ROI percentage]
  - [Payback period]
  - [NPV analysis]

#### Strategic Alignment
- [ ] **OKR alignment confirmed**
  - [OKR 1]: [How this supports]
  - [OKR 2]: [How this supports]
  - [OKR 3]: [How this supports]
- [ ] **Strategic fit assessed**
  - [Company vision alignment]
  - [Product strategy alignment]
  - [Market positioning alignment]

---

## 5. Synthesis & Decision (Week 4)

### 5.1 Evidence Synthesis
**Objective**: Synthesize all discovery evidence

#### Evidence Pack Creation
- [ ] **User research summary**
  - [Key user insights]
  - [Pain points prioritized]
  - [User needs documented]
- [ ] **Technical analysis summary**
  - [Feasibility assessment]
  - [Architecture approach]
  - [Implementation plan]
- [ ] **Business analysis summary**
  - [Market opportunity]
  - [Financial impact]
  - [Strategic alignment]

#### Opportunity Canvas
- [ ] **Opportunity canvas completed**
  - [Problem space defined]
  - [Solution space defined]
  - [Market opportunity assessed]
  - [Business impact quantified]

### 5.2 Decision Framework
**Objective**: Make go/no-go decision

#### Decision Criteria
- [ ] **User validation criteria met**
  - [User problem validated]
  - [User need confirmed]
  - [User solution validated]
- [ ] **Technical feasibility confirmed**
  - [Architecture viable]
  - [Performance achievable]
  - [Integration feasible]
- [ ] **Business case validated**
  - [Market opportunity confirmed]
  - [Financial impact positive]
  - [Strategic alignment confirmed]

#### Go/No-Go Decision
- [ ] **Decision made**
  - [ ] **GO** - Proceed to PRD development
  - [ ] **NO-GO** - Do not proceed
  - [ ] **ITERATE** - Refine and re-evaluate
- [ ] **Decision rationale documented**
  - [Key factors]
  - [Evidence supporting decision]
  - [Risks and mitigations]

---

## 6. Discovery Artifacts

### 6.1 Required Artifacts
- [ ] **User research report**
- [ ] **Telemetry analysis report**
- [ ] **Solution design document**
- [ ] **Technical feasibility assessment**
- [ ] **Business case document**
- [ ] **Opportunity canvas**
- [ ] **Decision rationale document**

### 6.2 Optional Artifacts
- [ ] **Competitive analysis**
- [ ] **Market research report**
- [ ] **User journey maps**
- [ ] **Wireframes/mockups**
- [ ] **Prototype**
- [ ] **Risk assessment**

---

## 7. Discovery Quality Checklist

### 7.1 User Research Quality
- [ ] Minimum 5 user interviews conducted
- [ ] Diverse user segments represented
- [ ] Interview questions well-designed
- [ ] Insights properly synthesized
- [ ] User needs clearly documented

### 7.2 Technical Analysis Quality
- [ ] Architecture approach defined
- [ ] Technical feasibility confirmed
- [ ] Performance requirements specified
- [ ] Integration approach planned
- [ ] Risks identified and mitigated

### 7.3 Business Analysis Quality
- [ ] Market opportunity quantified
- [ ] Financial impact calculated
- [ ] Strategic alignment confirmed
- [ ] ROI analysis completed
- [ ] Business case documented

### 7.4 Decision Quality
- [ ] All evidence synthesized
- [ ] Decision criteria met
- [ ] Stakeholders consulted
- [ ] Decision rationale documented
- [ ] Next steps defined

---

## 8. Discovery Best Practices

### 8.1 User Research Best Practices
- **Ask open-ended questions**: Avoid leading questions
- **Listen more than talk**: Let users share their experiences
- **Look for patterns**: Identify common themes across interviews
- **Validate assumptions**: Test your hypotheses with users
- **Document everything**: Record insights and quotes

### 8.2 Technical Analysis Best Practices
- **Start with constraints**: Understand technical limitations
- **Consider scalability**: Think about future growth
- **Plan for integration**: Consider existing systems
- **Assess risks early**: Identify potential technical risks
- **Get expert input**: Consult with technical experts

### 8.3 Business Analysis Best Practices
- **Quantify everything**: Use numbers to support decisions
- **Consider opportunity cost**: What else could we do?
- **Think long-term**: Consider future implications
- **Validate assumptions**: Test business hypotheses
- **Document rationale**: Explain your reasoning

---

## 9. Discovery Templates

### 9.1 User Interview Guide
- [Link to interview guide template]

### 9.2 Telemetry Analysis Template
- [Link to telemetry analysis template]

### 9.3 Solution Design Template
- [Link to solution design template]

### 9.4 Business Case Template
- [Link to business case template]

### 9.5 Opportunity Canvas Template
- [Link to opportunity canvas template]

---

## 10. Discovery Metrics

### 10.1 Discovery Quality Metrics
- **User interview completion rate**: % of planned interviews completed
- **Evidence pack completeness**: % of required artifacts created
- **Decision confidence**: Stakeholder confidence in decision
- **Implementation success**: % of discoveries that lead to successful implementations

### 10.2 Discovery Efficiency Metrics
- **Discovery duration**: Average days per discovery
- **Discovery throughput**: Discoveries completed per quarter
- **Decision accuracy**: % of decisions that prove correct
- **Iteration rate**: % of discoveries that require iteration

---

## 11. Appendices

### 11.1 Discovery Tools
- [Links to discovery tools]

### 11.2 Research Methods
- [Links to research methods]

### 11.3 Analysis Frameworks
- [Links to analysis frameworks]

### 11.4 Decision Frameworks
- [Links to decision frameworks]

### 5.1 Evidence Synthesis
**Objective**: Synthesize all discovery evidence

#### Evidence Pack Creation
- [ ] **User research summary**
  - [Key user insights]
  - [Pain points prioritized]
  - [User needs documented]
- [ ] **Technical analysis summary**
  - [Feasibility assessment]
  - [Architecture approach]
  - [Implementation plan]
- [ ] **Business analysis summary**
  - [Market opportunity]
  - [Financial impact]
  - [Strategic alignment]

#### Opportunity Canvas
- [ ] **Opportunity canvas completed**
  - [Problem space defined]
  - [Solution space defined]
  - [Market opportunity assessed]
  - [Business impact quantified]

### 5.2 Decision Framework
**Objective**: Make go/no-go decision

#### Decision Criteria
- [ ] **User validation criteria met**
  - [User problem validated]
  - [User need confirmed]
  - [User solution validated]
- [ ] **Technical feasibility confirmed**
  - [Architecture viable]
  - [Performance achievable]
  - [Integration feasible]
- [ ] **Business case validated**
  - [Market opportunity confirmed]
  - [Financial impact positive]
  - [Strategic alignment confirmed]

#### Go/No-Go Decision
- [ ] **Decision made**
  - [ ] **GO** - Proceed to PRD development
  - [ ] **NO-GO** - Do not proceed
  - [ ] **ITERATE** - Refine and re-evaluate
- [ ] **Decision rationale documented**
  - [Key factors]
  - [Evidence supporting decision]
  - [Risks and mitigations]

---

## 6. Discovery Artifacts

### 6.1 Required Artifacts
- [ ] **User research report**
- [ ] **Telemetry analysis report**
- [ ] **Solution design document**
- [ ] **Technical feasibility assessment**
- [ ] **Business case document**
- [ ] **Opportunity canvas**
- [ ] **Decision rationale document**

### 6.2 Optional Artifacts
- [ ] **Competitive analysis**
- [ ] **Market research report**
- [ ] **User journey maps**
- [ ] **Wireframes/mockups**
- [ ] **Prototype**
- [ ] **Risk assessment**

---

## 7. Discovery Quality Checklist

### 7.1 User Research Quality
- [ ] Minimum 5 user interviews conducted
- [ ] Diverse user segments represented
- [ ] Interview questions well-designed
- [ ] Insights properly synthesized
- [ ] User needs clearly documented

### 7.2 Technical Analysis Quality
- [ ] Architecture approach defined
- [ ] Technical feasibility confirmed
- [ ] Performance requirements specified
- [ ] Integration approach planned
- [ ] Risks identified and mitigated

### 7.3 Business Analysis Quality
- [ ] Market opportunity quantified
- [ ] Financial impact calculated
- [ ] Strategic alignment confirmed
- [ ] ROI analysis completed
- [ ] Business case documented

### 7.4 Decision Quality
- [ ] All evidence synthesized
- [ ] Decision criteria met
- [ ] Stakeholders consulted
- [ ] Decision rationale documented
- [ ] Next steps defined

---

## 8. Discovery Best Practices

### 8.1 User Research Best Practices
- **Ask open-ended questions**: Avoid leading questions
- **Listen more than talk**: Let users share their experiences
- **Look for patterns**: Identify common themes across interviews
- **Validate assumptions**: Test your hypotheses with users
- **Document everything**: Record insights and quotes

### 8.2 Technical Analysis Best Practices
- **Start with constraints**: Understand technical limitations
- **Consider scalability**: Think about future growth
- **Plan for integration**: Consider existing systems
- **Assess risks early**: Identify potential technical risks
- **Get expert input**: Consult with technical experts

### 8.3 Business Analysis Best Practices
- **Quantify everything**: Use numbers to support decisions
- **Consider opportunity cost**: What else could we do?
- **Think long-term**: Consider future implications
- **Validate assumptions**: Test business hypotheses
- **Document rationale**: Explain your reasoning

---

## 9. Discovery Templates

### 9.1 User Interview Guide
- [Link to interview guide template]

### 9.2 Telemetry Analysis Template
- [Link to telemetry analysis template]

### 9.3 Solution Design Template
- [Link to solution design template]

### 9.4 Business Case Template
- [Link to business case template]

### 9.5 Opportunity Canvas Template
- [Link to opportunity canvas template]

---

## 10. Discovery Metrics

### 10.1 Discovery Quality Metrics
- **User interview completion rate**: % of planned interviews completed
- **Evidence pack completeness**: % of required artifacts created
- **Decision confidence**: Stakeholder confidence in decision
- **Implementation success**: % of discoveries that lead to successful implementations

### 10.2 Discovery Efficiency Metrics
- **Discovery duration**: Average days per discovery
- **Discovery throughput**: Discoveries completed per quarter
- **Decision accuracy**: % of decisions that prove correct
- **Iteration rate**: % of discoveries that require iteration

---

## 11. Appendices

### 11.1 Discovery Tools
- [Links to discovery tools]

### 11.2 Research Methods
- [Links to research methods]

### 11.3 Analysis Frameworks
- [Links to analysis frameworks]

### 11.4 Decision Frameworks
- [Links to decision frameworks]